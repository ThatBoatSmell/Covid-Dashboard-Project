---
title: "Project Description Outline"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Names of group members

Stuart Stenhouse, Kirsty Anderson, Cailean Smith, David Craig

### Roles & responsibilities of each member

Stuart, I worked on analysing the differences in the number of admissions and the average length of stay between demographic groups - including gender, age and deprivation level. In addition, based on the brief, in each of these areas, I worked to present the data in a way which enabled comparison between pre and post-COVID-19. To do this, I started by gaining a base-level understanding of the data and potential relationships and completed initial wrangling and cleaning steps to allow me to create a range of different visualisations for each demographic group. Once I had an idea of the insights I wanted to highlight, I formalised the wrangling and cleaning steps before selecting the visualisations I felt communicated the insights most clearly. These were then presented to the rest of my group for consensus before being incorporated into the app. To support the insights and trends generated by visualising the data, I also completed a hypothesis test on each demographic group which generated evidence to suggest the following:

- There is a statistically significant difference in admission numbers between those over 50 and those under 50.
- There is a statistically significant difference in admission numbers between the highest and lowest deprivation groups.
- There is no statistically significant difference in the number of admissions between females and males.

I also worked on standardising the aesthetics of the app and its plots. To do this, along with my team members, we ensured that all visualisations prioritised the clear and accurate portrayal of data and were appropriate for a non-technical audience. This was achieved using descriptive titles and axis labels and ensuring that axis scales were appropriate. As a final step, colours from Public Health Scotland branding were applied throughout to enhance the app's aesthetic appeal and visualisations.

Kirsty worked on cleaning the “Beds by NHS board of treatment and speciality” data, 
as well as creating the plot and leaflet map from the “Trends by Location” tab, and finally creating the presentation.

Cailean worked on creating the initial framework of the app, helping to create visualisations based on the specialty data,helping to import everyone's initial work into the app framework and helping to maintain the app during merges and commits.

David worked on performed temporal analysis on the data sets and put together those visualisations. He also worked on completing the statistical analysis tab alongside the vsiualisations and intepretting the results of the analysis on key performance indicators.

Everyone had the opportunity to work different parts of the project in a collaborative manner.
This included; project presentation, app development, data analysis and exploration, and creating data visualizations. 

### Brief description of dashboard topic

Our dashboard contains a selection of visualisations relating to data captured by Public Health 
Scotland on the healthcare provided by the NHS in Scotland. It allows a user to view information 
on 3 central key performance indicators: number of patient admissions, length of patient episode, 
and percentage of beds occupied per NHS location, and how these indicators compare when analysed 
from the viewpoints of performance over time and between regions, demographics, and medical sectors. 
The data looks at these metrics from Q3 of 2017 to Q3 of 2022. The project was undertaken over a 7 day time course and due to the tight deadline we did not have the opportunity to revise and clean the code, something we would have done if given more time.

### Stages of the project

### Initial Discussion and Definitions

Upon receiving the project brief on Thursday we entered into the planning stage of the project
where we discussed the brief, broke down the project into two main sections and defined some
candidate key performance indicators (KPI's). 
Using Excalidraw we wrote down our definition of the media's "Winter Crisis", 
being an increase pressure on the NHS due to increases in seasonal and respiratory 
illnesses in the winter months. Our two main sections were the effects of this pre-2020
and post-2020. We also decided on our working hours being 9-5 on weekdays with a few hours of solo work in the evening.
We also agreed to only work 4-6 hours each over the coming weekend.

We then determined a plan for cleaning the data and each examined two of the 
provided data sets from Public Health Scotland to determine some candidate KPI's. 


We  narrowed this down to our final KPIs being:

- the number of episodes (as a proxy for number of admissions), 
- average length of patient hospital stay,
- percentage of hospital bed occupancy.

After deciding our KPI's to looking at the data we also drew some graphical representations
to what we expected this trend to look like, deciding that we wanted to segment the 
data into pre-2020 (2017-2019) vs post-2020 (2020-2022) for each metric. 

### Dashboard Wire frame 
We then began to put together a wire frame image of MVP version of the  app to look 
choosing to look at sections relating to temporal trends, geographical trends and 
trends in demographics for each of our KPIs. We also discussed how we would like 
to present the data and which chart types we wished to use. 

### GitHub
We also at this point set up a Git repository with each of us having a designated 
"development" branch for each group member separate from the main branch. We did not have set times
for merging branches together except for the end of each day but would come together to communicate and
make sure everyone was working on the same version of the app and work through any merge conflicts.

### Data Selection
We decided on the data sets we would analyse and then divided up the work evenly 
between each group member for the weekend with Cailean putting together a "skeleton" for the app 
and the rest of us analysing the data for either temporal, geographical or demographic trends.
We then cleaned our individual data sets with the goal over the weekend to have a selection of 
graphs and analysis to choose from to add to the app the following week.

We also put together a rough plan of our goals for the following week and decided we 
would try to have 3 main versions of the app finished at the end of each day 
and then go back to improve or change the previous day's app. We decided to have 
3 short meetings a day to keep each other up to date and troubleshoot.

### Shiny App Version 1

After the weekend we came together to put the first version of the app together 
and took it in turns to work with Cailean to update his app skeleton. David also 
combined all our cleaning scripts for each data set into one usable file. After 
putting the app together we also planned Monday evening's work to further improve 
the app and decided to consult with the instructors regarding the statistical 
analysis we wished to perform and add to the app. 

### Shiny App Version 2
Tuesday during the day we all worked on our respective areas adding increased 
functionality to the app in terms of selections and drop down menus. Cailean also
took responsibility for looking at differences in hospital specialties as part of 
our analysis. David performed some of the initial statistical analyses for the app
and Stuart and Kirsty began to piece together the project presentation. By the end of
the day we had a second working version of the app with added statistics and updated plots.
We then designated responsibilities for the evening which included Stuart working on
app aesthetics and formatting, Cailean updating the formatting of the app and Kirsty
adding a Geographical heat map.

### Shiny App Version 3

On Wednesday we continued to improve the aesthetics of the app, making additions to the 
layout and graphs as well as adding the specialty graphs from Cailean. We also worked on the presentation
and spent the afternoon working out bugs with the app to make sure all our functions and 
additions worked as we wanted. By the end of the day we had an almost finished version of the app
and we decided in the evening to add labels and text to each of the tabs in the app we had been working on
and Stuart also added in some additional statistical analysis.

### Final App and Presentation

On the Thursday morning we did a final run of the app checking all functionality 
and doing minor updates to the aesthetics. Afterwards we focused on completing our
presentation and presentation practice. 

### Which tools were used in the project

Tools
For this project, we used:
Zoom: For stand-ups and paired/group working
and for general "work hours" communication
Slack: For discussion out of "work hours", 
to keep in contact regarding anything we 
were having issues with and general
updates
RStudio: To develop our app and code-base
Excalidraw: For designing our framework, keeping ideas
together and allowing collaborative input  
GitHub: For version control, working on our own branches and
for collaborating
Google Slides: for creating our presentation   

### How did you gather and synthesise requirements for the project?

Gathering and synthesising
We synthesised the information given in the brief by working through the brief and discussing 
what points we wanted to focus on, as well as looking through the datasets recommended to
gain a better understanding of what direction we could go in.
We prioritised getting an "MVP" version of the app running - at every point, we made sure that
we were not straying too far from our framework

Once we had the "MVP" version of the app, we then prioritised polishing each aspect, always referring back to the
brief to make sure we were still working in the correct direction.

### Motivations for using the data you have chosen

We used several datasets in this project.
The dataset “Activity by Board of Treatment and Deprivation ” allowed us to gain insight on ‘the number of admissions’ 
and ‘length of stay’ metrics across the 5 SIMD levels within each healthboard. This allowed us to investigate how the 
number of admissions and length of episode changed within each SIMD level and if this fluctuated over the Q3 2017 to Q3 2022 timeframe. 

The dataset “Inpatient and Daycase by NHS board of treatment” provided data on the number of admissions in each 
quarter per NHS location and NHS health board in general, and then further categorised each admission into 
demographics such as age and sex, and also the relevant medical speciality. This allowed us to research how admission numbers and episode length differed over the provided time frame, and also how they differed 
between age, sex, and medical speciality. 
The dataset “Beds by NHS Board of Treatment and Speciality” gave the percentage of occupied beds, as well as average number of occupied beds, in each NHS location (e.g. hospitals), in each of the annual quarters, and further specified this by medical specialty. This allowed us to show how the percentage occupancy and number of occupied beds varied across NHS locations throughout the timeframe, as well as visualise how percentage occupancy changed across the health boards. It also allowed us to look at the difference in occupancy rates per medical sector and if this varied with time. The dataset “Current NHS Hospital Locations” gave us the geographical points of NHS locations which we could then plot in a geographic format and use coloured visualisations to show the occupancy at these locations at a given point in time 
across the timeframe.

### Data quality and potential bias, including a brief summary of data cleaning and transformations.

According to Public Health Scotland, the data sets used are designated National Statistics by the UK Statistics Authority, meaning they comply with the Code of Practice for Statistics, designed to ensure trustworthiness, quality and value. However, it is noted by Public Health Scotland that although data is made available for each quarter, NHS boards can submit data monthly, which may result in some variation in quarterly data and impact analysis.

Regarding potential bias, the platform through which the data used is available contains a range of features that support transparency and reduce the risk of bias. These include an "Activity Stream" where users can see details of updates to each data set, the inclusion of a "Data Dictionary" and additional data including Revision IDs, creation dates etc.

The data wrangling and cleaning approach was generally similar across all data sets. Likewise, similar R Packages were used by all team members to support cleaning - namely Tidyverse and Janitor. Once the data had been read into RStudio, variable names were cleaned using Janitor and a range of Tidyverse functions were used to wrangle and clean the data. Examples of the Tidyverse functions used are included below:

Select & Filter: Used to identify and extract the required data from the data sets.
Mutate: Used to create new and modify existing data, for example, by mapping Health Board codes to Health Board names.
Summarise: Used to create a range of summary values (e.g. mean hospital admissions for a quarter across multiple years).
Separate: Used to separate year and quarter data for more flexible exploratory analysis and data visualisation.
Stringr: Remove and Trim functions from the StringR package, part of the tidyverse, were used to tidy age data for clearer visualisation.

All efforts were made to utilise as much of the available data as possible; unfortunately, complete data was not always available. We discussed different approaches in these situations, including imputing data based on other available information. However, to support consistency and accuracy while ensuring we utilised as much available data as possible, where data was unavailable, these individual observations were dropped. 

### How is the data stored and structured?

The data is in the form csv files which are accessible for download on the Public 
Health Scotland website. They are also accessible via the website as an interactive dashboard and you can manipulate certain variables to plot graphs. The data does not contain any personal identifiable or sensitive information therefore working with these data sets did not raise any ethical concerns.

The data on Public Health Scotland is also known as Linked Data. This means in simple terms that this data can be linked to and any unique data point in a linked data set should have a unique URL. This is beneficial in that the data point can be easily browsed on a web page and referenced in other linked data sets. 
The principle behind linked data is that each data point is formed of three peices of information the subject-predicate -object arrangement. The subject and object are joined by the predicate and together may form a statement 

ie subject = Steve, predicate = hasHairColour, object = red.


### Ethical and legal considerations of the data

All data used in the project was sourced from Public Health Scotland and downloaded from the "Scottish Health and Social Care Open Data" platform. All data used is made available under the UK Governments Open Government Licence. This license enables users to copy, publish, distribute and transmit the data and adapt and exploit it in commercial or non-commercial activities. A requirement of using data under this license is that the source of information, in our instance Public Health Scotland, must be acknowledged, and in our case, this was done in the footer of each page on the app.

An individual's right to privacy and confidentiality is a critical ethical consideration in all data analysis projects. This is particularly the case when working with sensitive health data; however, data made available under the Open Government Licence does not cover personal data, and no confidential or identifying data was included in the data used.
